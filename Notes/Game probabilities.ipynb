{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game probabilities\n",
    "\n",
    "The purpose of this notebook is to figure out how we plan to measure the strength of our models predictions vs how \"likely\" a game is to be won. Obviously there is no direct measure of probability for a game (i.e. no one can say with certainty that \"there's a 75% chance team X will beat team Y\"), so we need to think of how we measure this. That's the purpose of this notebook.\n",
    "\n",
    "This notebook should be ideas/thoughts, not code (or only very minimal code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring win probability\n",
    "\n",
    "_After_ a game is completed, are there things we can look back at that indicate how likely it was that a certain team would win?\n",
    "\n",
    "- Win-Loss Percentage- This gives a sense of who the underdog is and which team should have won. If a team has a W-L of 70% against a team with 35% you would expect the team that wins more to win. On the other hand, if a team has a 54% win percentage against a 56% then it would be harder to pick which team would win definitively.\n",
    "- W-L% can be formalized to win probability by following [this article](https://sabr.org/journal/article/probabilities-of-victory-in-head-to-head-team-matchups/).\n",
    "\n",
    "_A question I have is, are any of the models predicting more games right when an underdog wins on average than if we were to just pick the home team winning (base model) each time?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring model prediction strength\n",
    "\n",
    "Some models (such as XGB, NN and logistic regression) have built-in prediction probabilities. Some (like KNN or ensembles) do not. For models that do _not_ have such a probability attached to them, how can we measure their probability?\n",
    "\n",
    "- KNN\n",
    "    - Return the neighbors and what find what proportion of them had the predicted value for `home_win`\n",
    "- Ensembles\n",
    "    - [Weighted average ensemble](https://machinelearningmastery.com/weighted-average-ensemble-for-deep-learning-neural-networks/) by using their accuracy on the test set. Then we can also weight their probabilities, or just weight the predictions. So for example, if all weights are equal and two models predict 1 and one predicts 0, then the \"probability\" would be $0\\cdot \\frac13 + 1\\cdot \\frac13 + 1\\cdot \\frac13 = \\frac23$. The problem with this approach is that the only possible values are 0, $\\frac13$, $\\frac23$ and 1. So maybe working with the probabilities is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tieing model prediction to win probability\n",
    "\n",
    "Once we have decided on ways to measure win probability for a game and win probability for a model, how do we tie these two together?\n",
    "\n",
    "- Cumulative distribution function (CDF) - A CDF is a graph with the x-axis being the model probability (so 0 to 1) and the y-axis being the percentage of games which were predicted correctly by the model, based on their model predicted win probability. So for example, if we look at a model and see that, for all games with a predicted win probability of 25% or less, only 15% of them were predicted correctly, then we would plot the point (0.25, 0.15). Repeat this for all model probabilities between 0 and 1.\n",
    "- Scatterplot comparing model prediction on x-axis and any measure from \"measuring win probability\" (above) on the y-axis.\n",
    "- Area under precision-recall curve and ROC - These are two common statistical measures for binary classification problems. They both try to reward models whose prediction strength correspond well with positive outcomes, and penalize models who don't. They're both simple curves to make that sklearn has built in, and the number associated with them is just an integral to get area under that curve (also built in to sklearn)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
