{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization\n",
    "\n",
    "The point of this notebook is to use the [Bayesian optimization package](https://github.com/fmfn/BayesianOptimization) to do an intelligent hyperparameter search for XGB. In this notebook we'll run hyperparameter tuning on the XGB model. I'm following both the documentation on the package github page, along with [this Kaggle tutorial](https://www.kaggle.com/tilii7/bayesian-optimization-of-xgboost-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Final Data/pct-diff-mlb-games.csv')  #Pct Diff Columns Only (Gives Highest Accuracy)\n",
    "#df = pd.read_csv('../data/Final Data/diff-mlb-games.csv')    #Diff columns only\n",
    "#df = pd.read_csv('../data/Final Data/full-diff-mlb-games.csv')    #All columns\n",
    "\n",
    "train_df = df[df['Y'] <= 2015]\n",
    "test_df = df[df['Y'] > 2015]\n",
    "\n",
    "X_train = train_df.drop('home_win', axis=1)\n",
    "y_train = train_df.home_win\n",
    "\n",
    "X_test = test_df.drop('home_win', axis=1)\n",
    "y_test = test_df.home_win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open('AUC-5fold-XGB.log', 'a')\n",
    "AUCbest = -1.0\n",
    "ITERbest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(max_depth, min_child_weight, eta, subsample, colsample_bytree, gamma):\n",
    "    global AUCbest\n",
    "    global ITERbest\n",
    "    \n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'eta': eta,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'gamma': gamma,\n",
    "              'seed': 0,\n",
    "              'nthread': 4,\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'auc'}\n",
    "    \n",
    "    folds = 5\n",
    "    cv_score = 0\n",
    "    \n",
    "    print(\"\\n Search parameters (%d-fold validation):\\n %s\" % (folds, params), file=log_file)\n",
    "    log_file.flush()\n",
    "\n",
    "    xgbc = xgb.cv(\n",
    "                    params,\n",
    "                    dtrain,\n",
    "                    num_boost_round = 20000,\n",
    "                    stratified = True,\n",
    "                    nfold = folds,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    metrics = 'auc',\n",
    "                    show_stdv = True\n",
    "               )\n",
    "    \n",
    "    val_score = xgbc['test-auc-mean'].iloc[-1]\n",
    "    train_score = xgbc['train-auc-mean'].iloc[-1]\n",
    "    print('Stopped after %d iterations with train-auc = %f val-auc = %f ( diff = %f ) train-gini = %f val-gini = %f' % ( len(xgbc), train_score, val_score, (train_score - val_score), (train_score*2-1),\n",
    "(val_score*2-1)))\n",
    "    if val_score > AUCbest:\n",
    "        AUCbest = val_score\n",
    "        ITERbest = len(xgbc)\n",
    "\n",
    "    return (val_score*2) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': (3, 20),\n",
    "          'min_child_weight': (0.001, 10),\n",
    "          'eta': (0.001, 1.0),\n",
    "          'subsample': (0.6, 1.0),\n",
    "          'colsample_bytree': (0.6, 1.0),\n",
    "          'gamma': (0.001, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_BO = BayesianOptimization(xgb_cv, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    |   gamma   | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Stopped after 4 iterations with train-auc = 0.745929 val-auc = 0.630198 ( diff = 0.115732 ) train-gini = 0.491858 val-gini = 0.260395\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2604  \u001b[0m | \u001b[0m 0.998   \u001b[0m | \u001b[0m 0.4927  \u001b[0m | \u001b[0m 1.951   \u001b[0m | \u001b[0m 11.0    \u001b[0m | \u001b[0m 8.283   \u001b[0m | \u001b[0m 0.613   \u001b[0m |\n",
      "Stopped after 7 iterations with train-auc = 0.722569 val-auc = 0.656329 ( diff = 0.066239 ) train-gini = 0.445137 val-gini = 0.312658\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3127  \u001b[0m | \u001b[95m 0.6723  \u001b[0m | \u001b[95m 0.4543  \u001b[0m | \u001b[95m 9.524   \u001b[0m | \u001b[95m 9.171   \u001b[0m | \u001b[95m 3.086   \u001b[0m | \u001b[95m 0.885   \u001b[0m |\n",
      "Stopped after 8 iterations with train-auc = 0.689124 val-auc = 0.666155 ( diff = 0.022969 ) train-gini = 0.378248 val-gini = 0.332310\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.3323  \u001b[0m | \u001b[95m 0.9476  \u001b[0m | \u001b[95m 0.3077  \u001b[0m | \u001b[95m 9.664   \u001b[0m | \u001b[95m 5.348   \u001b[0m | \u001b[95m 0.3256  \u001b[0m | \u001b[95m 0.8243  \u001b[0m |\n",
      "Stopped after 4 iterations with train-auc = 0.673150 val-auc = 0.662702 ( diff = 0.010447 ) train-gini = 0.346299 val-gini = 0.325404\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.3254  \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 0.9262  \u001b[0m | \u001b[0m 3.465   \u001b[0m | \u001b[0m 3.423   \u001b[0m | \u001b[0m 0.05835 \u001b[0m | \u001b[0m 0.8526  \u001b[0m |\n",
      "Stopped after 1594 iterations with train-auc = 0.788748 val-auc = 0.664077 ( diff = 0.124671 ) train-gini = 0.577497 val-gini = 0.328155\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3282  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "XGB_BO.maximize(init_points=2, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': int(XGB_BO.max['params']['max_depth']),\n",
    "              'min_child_weight': XGB_BO.max['params']['min_child_weight'],\n",
    "              'eta': XGB_BO.max['params']['eta'],\n",
    "              'subsample': XGB_BO.max['params']['subsample'],\n",
    "              'colsample_bytree': XGB_BO.max['params']['colsample_bytree'],\n",
    "              'gamma': XGB_BO.max['params']['gamma'],\n",
    "              'seed': 0,\n",
    "              'nthread': 4,\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'auc'}\n",
    "\n",
    "xgb_best = xgb.train(best_params, dtrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_child_weight': 0.3256355793000354,\n",
       " 'eta': 0.3076951770384403,\n",
       " 'subsample': 0.8242904472901268,\n",
       " 'colsample_bytree': 0.9475703665037462,\n",
       " 'gamma': 9.66425615956974,\n",
       " 'seed': 0,\n",
       " 'nthread': 4,\n",
       " 'objective': 'binary:logistic',\n",
       " 'eval_metric': 'auc'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_proba = xgb_best.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.round(test_preds_proba, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57      4551\n",
      "           1       0.63      0.71      0.67      5167\n",
      "\n",
      "    accuracy                           0.63      9718\n",
      "   macro avg       0.62      0.62      0.62      9718\n",
      "weighted avg       0.62      0.63      0.62      9718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6255402346161761"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
