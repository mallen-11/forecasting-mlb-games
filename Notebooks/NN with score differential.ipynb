{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final models\n",
    "\n",
    "The purpose of this notebook is to collect \"final versions\" of the models we want to use for ensembling. These will all use the same data (though they can certainly omit columns if you want). The point is to go from zero-to-trained model in one notebook so we can make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.data_loader import Dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Load the data here. Models below can augment it if need-be (for example the neural net needs it as a tensorflow dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/start_to_finish.csv')  #Pct Diff Columns Only (Gives Highest Accuracy)\n",
    "# df = pd.read_csv('../data/Final Data/pct-diff-mlb-games.csv')  #Pct Diff Columns Only (Gives Highest Accuracy)\n",
    "#df = pd.read_csv('../data/Final Data/diff-mlb-games.csv')    #Diff columns only\n",
    "# df = pd.read_csv('../data/Final Data/full-diff-mlb-games.csv')    #All columns\n",
    "\n",
    "cols = ['team_ops_pct_diff', 'obp_diff', 'team_obp_pct_diff',\n",
    "       'home_Rank_offset1year', 'away_WHIP_offset1year', 'team_ERA_pct_diff',\n",
    "       'home_win_diff_bayes', 'home_RD', 'team_bayes_pct_diff',\n",
    "       'away_win_diff_bayes'] + ['Y', 'M', 'home_win', 'home_team', 'away_team']\n",
    "\n",
    "# cols = ['home_win', 'home_team', 'away_team', 'Y', 'M', 'avg_pct_diff',\n",
    "#        'obp_pct_diff', 'slg_pct_diff', 'team_ERA_pct_diff',\n",
    "#        'team_WHIP_pct_diff', 'team_W-L_pct_diff', 'team_Rank_pct_diff',\n",
    "#        'team_FP_pct_diff', 'team_R_pct_diff', 'team_RA_pct_diff', 'team_pytha_pct_diff',\n",
    "#        'team_W-L_pct_diff', 'team_bayes_pct_diff', 'pitcher_WHIP_pct_diff',\n",
    "#        'pitcher_ERA_pct_diff', 'pitcher_IP_pct_diff', 'team_ops_pct_diff',\n",
    "#        'RD_pct_diff', 'FP_pct_diff', 'Rank_pct_diff', 'team_WPA_pct_diff', 'log_5']\n",
    "\n",
    "\n",
    "def train_test_split(df, include_teams=False):\n",
    "    if not include_teams:\n",
    "        df = df.drop(['home_team', 'away_team'], axis='columns')\n",
    "    \n",
    "    train_df = df[df['Y'] <= 2015]\n",
    "    test_df = df[df['Y'] > 2015]\n",
    "\n",
    "    X_train = train_df.drop('home_win', axis=1)\n",
    "    y_train = train_df.home_win\n",
    "\n",
    "    X_test = test_df.drop('home_win', axis=1)\n",
    "    y_test = test_df.home_win\n",
    "    \n",
    "    return X_train, y_train, train_df, X_test, y_test, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Y', 'M', 'home_team', 'away_team', 'home_win', 'home_elo', 'away_elo',\n",
       "       'home_avg', 'away_avg', 'home_obp', 'away_obp', 'home_slg', 'away_slg',\n",
       "       'home_iso', 'away_iso', 'elo_diff', 'elo_pct_diff', 'avg_diff',\n",
       "       'obp_diff', 'slg_diff', 'team_avg_pct_diff', 'team_obp_pct_diff',\n",
       "       'team_slg_pct_diff', 'home_rest', 'away_rest',\n",
       "       'home_W-L-pct_offset1year', 'home_Avg_Attendance_offset1year',\n",
       "       'home_Rank_offset1year', 'home_R_offset1year', 'home_RA_offset1year',\n",
       "       'home_FP_offset1year', 'away_W-L-pct_offset1year',\n",
       "       'away_Avg_Attendance_offset1year', 'away_Rank_offset1year',\n",
       "       'away_R_offset1year', 'away_RA_offset1year', 'away_FP_offset1year',\n",
       "       'home_WHIP_offset1year', 'home_ERA_offset1year',\n",
       "       'away_WHIP_offset1year', 'away_ERA_offset1year',\n",
       "       'home_pitcher_season_game', 'home_pitcher_WHIP_avg_162games',\n",
       "       'home_pitcher_ERA_avg_162games', 'home_pitcher_IP_avg_162games',\n",
       "       'home_pitcher_WPA_avg_162games', 'away_pitcher_season_game',\n",
       "       'away_pitcher_WHIP_avg_162games', 'away_pitcher_ERA_avg_162games',\n",
       "       'away_pitcher_IP_avg_162games', 'away_pitcher_WPA_avg_162games',\n",
       "       'home_total_R', 'home_total_RA', 'away_total_R', 'away_total_RA',\n",
       "       'home_win_pct', 'away_win_pct', 'home_pythag_expect',\n",
       "       'away_pythag_expect', 'home_win_diff', 'away_win_diff',\n",
       "       'home_previous_WL', 'away_previous_WL', 'home_bayes_win',\n",
       "       'away_bayes_win', 'home_win_diff_bayes', 'away_win_diff_bayes',\n",
       "       'home_ops', 'away_ops', 'home_RD', 'away_RD', 'pitcher_WHIP_pct_diff',\n",
       "       'pitcher_ERA_pct_diff', 'pitcher_IP_pct_diff', 'team_W-L_pct_diff',\n",
       "       'team_ops_pct_diff', 'team_RD_pct_diff', 'team_FP_pct_diff',\n",
       "       'team_Rank_pct_diff', 'team_ERA_pct_diff', 'team_RA_pct_diff',\n",
       "       'team_R_pct_diff', 'team_bayes_pct_diff', 'team_pytha_pct_diff',\n",
       "       'log_5', 'team_WHIP_pct_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gcar</th>\n",
       "      <th>Gtm</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Inngs</th>\n",
       "      <th>Dec</th>\n",
       "      <th>DR</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>Home_Tm</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>Result</th>\n",
       "      <th>Tm_Score</th>\n",
       "      <th>Opp_Score</th>\n",
       "      <th>name</th>\n",
       "      <th>DFS(DK)</th>\n",
       "      <th>DFS(FD)</th>\n",
       "      <th>Year</th>\n",
       "      <th>season_game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498</td>\n",
       "      <td>57</td>\n",
       "      <td>2000-06-05</td>\n",
       "      <td>CHC</td>\n",
       "      <td>CHC</td>\n",
       "      <td>GS-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1.904762</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>morgami01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>501</td>\n",
       "      <td>64</td>\n",
       "      <td>2000-06-13</td>\n",
       "      <td>LAD</td>\n",
       "      <td>LAD</td>\n",
       "      <td>GS-5</td>\n",
       "      <td>L(1-1)</td>\n",
       "      <td>2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>LAN</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>morgami01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506</td>\n",
       "      <td>79</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>CIN</td>\n",
       "      <td>CIN</td>\n",
       "      <td>GS-5</td>\n",
       "      <td>L(3-2)</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>ARI</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>L</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>morgami01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>97</td>\n",
       "      <td>2000-07-21</td>\n",
       "      <td>ARI</td>\n",
       "      <td>CIN</td>\n",
       "      <td>GS-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>CIN</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>W</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>morgami01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541</td>\n",
       "      <td>11</td>\n",
       "      <td>2001-04-14</td>\n",
       "      <td>ARI</td>\n",
       "      <td>COL</td>\n",
       "      <td>GS-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>COL</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>L</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>morgami01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gcar  Gtm        Date   Tm  Opp Inngs     Dec  DR   IP   H  ...  Home_Tm  \\\n",
       "0   498   57  2000-06-05  CHC  CHC  GS-5     NaN   5  4.2   5  ...      CHN   \n",
       "1   501   64  2000-06-13  LAD  LAD  GS-5  L(1-1)   2  4.2   8  ...      LAN   \n",
       "2   506   79  2000-06-30  CIN  CIN  GS-5  L(3-2)   2  5.0   8  ...      ARI   \n",
       "3   512   97  2000-07-21  ARI  CIN  GS-5     NaN   2  5.0  10  ...      CIN   \n",
       "4   541   11  2001-04-14  ARI  COL  GS-4     NaN   2  4.0   8  ...      COL   \n",
       "\n",
       "       WHIP  Result  Tm_Score  Opp_Score       name  DFS(DK)  DFS(FD)  Year  \\\n",
       "0  1.904762       L         3          4  morgami01      NaN      NaN  2000   \n",
       "1  2.380952       L         1          6  morgami01      NaN      NaN  2000   \n",
       "2  2.000000       L         4          5  morgami01      NaN      NaN  2000   \n",
       "3  2.400000       W         5          4  morgami01      NaN      NaN  2000   \n",
       "4  2.000000       L         8          9  morgami01      NaN      NaN  2001   \n",
       "\n",
       "   season_game  \n",
       "0         21.0  \n",
       "1         24.0  \n",
       "2         29.0  \n",
       "3         35.0  \n",
       "4          4.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df = pd.read_csv('../data/pitchers_games.csv')\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['date'] = pd.to_datetime(games_df['Date'])\n",
    "games_df['Y'] = games_df['Date'].dt.year\n",
    "games_df['M'] = games_df['Date'].dt.month\n",
    "games_df['home_team'] = games_df['Home_Tm']\n",
    "games_df['score_diff'] = games_df['Tm_Score'] - games_df['Opp_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_team(x):\n",
    "    if x['home_team'] == x['Tm']:\n",
    "        return x['Opp']\n",
    "    else:\n",
    "        return x['Tm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['away_team'] = games_df.apply(away_team, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape[0] = 47131\n",
      "games_df.shape[0] = 97955\n",
      "merged_df.shape[0] = 177717\n"
     ]
    }
   ],
   "source": [
    "merge_cols = ['Y', 'M', 'home_team', 'away_team']\n",
    "games_df_cols = ['score_diff']\n",
    "\n",
    "merged_df = df.merge(games_df[merge_cols + games_df_cols], on=merge_cols)\n",
    "print(f'df.shape[0] = {df.shape[0]}')\n",
    "print(f'games_df.shape[0] = {games_df.shape[0]}')\n",
    "print(f'merged_df.shape[0] = {merged_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, train_df, X_test, y_test, test_df = train_test_split(df[cols])\n",
    "X_train_all, _, train_df_all, X_test_all, _, test_df_all = train_test_split(df)\n",
    "X_train_nn, _, train_df_nn, X_test_nn, _, test_df_nn = train_test_split(df[cols], include_teams=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_inf(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].isin([-np.inf, np.inf]).sum() > 0:\n",
    "            df[c] = df[c].replace([-np.inf, np.inf], None)\n",
    "        if df[c].isna().sum() > 0:\n",
    "            med = df[c].median()\n",
    "            df[c] = df[c].fillna(med)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn data\n",
    "train_df_nn = fill_na_inf(train_df_nn)\n",
    "test_df_nn = fill_na_inf(test_df_nn)\n",
    "\n",
    "X_train_nn = fill_na_inf(X_train_nn)\n",
    "X_test_nn = fill_na_inf(X_test_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    if dtype == 'string':\n",
    "        index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "    \n",
    "    if name == 'home_team':\n",
    "        print('home_team')\n",
    "        print(index.get_vocabulary())\n",
    "        \n",
    "    if name == 'away_team':\n",
    "        print('away_team')\n",
    "        print(index.get_vocabulary())\n",
    "\n",
    "    # Create a Discretization for our integer indices.\n",
    "    encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    # Learn the space of possible indices.\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "    # layer so we can use them, or include them in the functional model later.\n",
    "    return lambda feature: encoder(index(feature))\n",
    "\n",
    "def prep_columns(dataset, embedding_dims=10, embedding_cols=None, numeric_cols=None):\n",
    "    cont_inputs = []\n",
    "    cat_inputs = []\n",
    "    encoded_cont_features = []\n",
    "    encoded_cat_features = []\n",
    "    if isinstance(embedding_dims, int):\n",
    "        embedding_dims = [embedding_dims] * len(embedding_cols)\n",
    "    assert len(embedding_dims) == len(embedding_cols), 'embedding_dims must be an integer or a list with the same length as embedding_cols'\n",
    "\n",
    "    # Numeric features.\n",
    "    for header in numeric_cols:\n",
    "        numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "        normalization_layer = get_normalization_layer(header, dataset)\n",
    "        encoded_numeric_col = normalization_layer(numeric_col)\n",
    "        encoded_numeric_col = tf.keras.layers.Dropout(0.1)(encoded_numeric_col)\n",
    "        cont_inputs.append(numeric_col)\n",
    "        encoded_cont_features.append(encoded_numeric_col)\n",
    "\n",
    "    # Home and away teams\n",
    "    for i, header in enumerate(['home_team', 'away_team']):\n",
    "        categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "        encoded_categorical_col = tf.keras.layers.Embedding(30, embedding_dims[i], name=f'{header}_embedding')(categorical_col)\n",
    "        encoded_categorical_col = tf.keras.layers.Flatten()(encoded_categorical_col)\n",
    "        cat_inputs.append(categorical_col)\n",
    "        encoded_cat_features.append(encoded_categorical_col)\n",
    "        \n",
    "    # Categorical features encoded as ints.\n",
    "    encoded_embedding_cols = embedding_cols.copy()\n",
    "    encoded_embedding_cols.remove('home_team')\n",
    "    encoded_embedding_cols.remove('away_team')\n",
    "    for i, header in enumerate(encoded_embedding_cols):\n",
    "        categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int64')\n",
    "        encoding_layer = get_category_encoding_layer(header, dataset, \n",
    "                                                     dtype='int', \n",
    "                                                     max_tokens=20)\n",
    "        encoded_categorical_col = encoding_layer(categorical_col)\n",
    "        encoded_categorical_col = tf.keras.layers.Embedding(20, 5, name=f'{header}_embedding')(encoded_categorical_col)\n",
    "        encoded_categorical_col = tf.keras.layers.Flatten()(encoded_categorical_col)\n",
    "        cat_inputs.append(categorical_col)\n",
    "        encoded_cat_features.append(encoded_categorical_col)\n",
    "        \n",
    "    all_inputs = cont_inputs + cat_inputs\n",
    "        \n",
    "    return all_inputs, encoded_cont_features, encoded_cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tensorflow dataset from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds(df):\n",
    "    cols_to_drop = ['home_pitcher', 'away_pitcher', 'date']\n",
    "    cols_to_drop = list(set(df.columns).intersection(set(cols_to_drop)))\n",
    "    df = df.drop(cols_to_drop, axis='columns')\n",
    "    \n",
    "    embedding_cols = ['home_team', 'away_team', 'Y', 'M']\n",
    "    numeric_cols = list(set(df.columns) - set(embedding_cols))\n",
    "    numeric_cols.remove('home_win')\n",
    "    assert set(numeric_cols).intersection(set(embedding_cols)) == set()\n",
    "    assert len(embedding_cols) + len(numeric_cols) + 1 == len(df.columns)\n",
    "    \n",
    "    df = fill_na_inf(df)\n",
    "            \n",
    "    le = LabelEncoder()\n",
    "    df['away_team'] = le.fit_transform(df['away_team'])\n",
    "    df['home_team'] = le.transform(df['home_team'])\n",
    "    \n",
    "    for c in embedding_cols:\n",
    "        df[c] = df[c].astype(int)\n",
    "        \n",
    "    assert df.isna().sum().sum() == 0\n",
    "    \n",
    "    y = df.pop('home_win')\n",
    "    y = y.astype(int)\n",
    "    X = df\n",
    "    \n",
    "    tf_ds = tf.data.Dataset.from_tensor_slices((dict(X), y)).batch(128)\n",
    "    return tf_ds, df, le, embedding_cols, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, tf_train_df, le, embedding_cols, numeric_cols = load_ds(train_df_nn)\n",
    "test_ds, tf_test_df, _, _, _ = load_ds(test_df_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs, encoded_cont_features, encoded_cat_features = prep_columns(train_ds,\n",
    "                                                                       10,\n",
    "                                                                       embedding_cols, \n",
    "                                                                       numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = concatenate(encoded_cat_features + encoded_cont_features)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output = Dense(1)(x)\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "291/291 [==============================] - 4s 5ms/step - loss: 0.7243 - accuracy: 0.5589 - val_loss: 0.6561 - val_accuracy: 0.5356\n",
      "Epoch 2/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6649 - accuracy: 0.5744 - val_loss: 0.6486 - val_accuracy: 0.5797\n",
      "Epoch 3/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6559 - accuracy: 0.5764 - val_loss: 0.6493 - val_accuracy: 0.5856\n",
      "Epoch 4/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6520 - accuracy: 0.5770 - val_loss: 0.6479 - val_accuracy: 0.5876\n",
      "Epoch 5/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6497 - accuracy: 0.5802 - val_loss: 0.6476 - val_accuracy: 0.5890\n",
      "Epoch 6/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6490 - accuracy: 0.5818 - val_loss: 0.6481 - val_accuracy: 0.5894\n",
      "Epoch 7/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6473 - accuracy: 0.5806 - val_loss: 0.6477 - val_accuracy: 0.5926\n",
      "Epoch 8/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6463 - accuracy: 0.5866 - val_loss: 0.6481 - val_accuracy: 0.5916\n",
      "Epoch 9/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6459 - accuracy: 0.5842 - val_loss: 0.6482 - val_accuracy: 0.5898\n",
      "Epoch 10/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6443 - accuracy: 0.5858 - val_loss: 0.6478 - val_accuracy: 0.5917\n",
      "Epoch 11/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6441 - accuracy: 0.5865 - val_loss: 0.6482 - val_accuracy: 0.5913\n",
      "Epoch 12/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6446 - accuracy: 0.5861 - val_loss: 0.6486 - val_accuracy: 0.5906\n",
      "Epoch 13/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6440 - accuracy: 0.5883 - val_loss: 0.6492 - val_accuracy: 0.5951\n",
      "Epoch 14/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6427 - accuracy: 0.5914 - val_loss: 0.6500 - val_accuracy: 0.5928\n",
      "Epoch 15/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6416 - accuracy: 0.5885 - val_loss: 0.6491 - val_accuracy: 0.5942\n",
      "Epoch 16/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6420 - accuracy: 0.5884 - val_loss: 0.6511 - val_accuracy: 0.5959\n",
      "Epoch 17/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6420 - accuracy: 0.5924 - val_loss: 0.6499 - val_accuracy: 0.5846\n",
      "Epoch 18/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6422 - accuracy: 0.5939 - val_loss: 0.6513 - val_accuracy: 0.5921\n",
      "Epoch 19/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6410 - accuracy: 0.5934 - val_loss: 0.6504 - val_accuracy: 0.5928\n",
      "Epoch 20/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6406 - accuracy: 0.5941 - val_loss: 0.6498 - val_accuracy: 0.5961\n",
      "Epoch 21/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6402 - accuracy: 0.5925 - val_loss: 0.6521 - val_accuracy: 0.5938\n",
      "Epoch 22/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6382 - accuracy: 0.6002 - val_loss: 0.6533 - val_accuracy: 0.5938\n",
      "Epoch 23/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6393 - accuracy: 0.5993 - val_loss: 0.6538 - val_accuracy: 0.5955\n",
      "Epoch 24/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6383 - accuracy: 0.6000 - val_loss: 0.6542 - val_accuracy: 0.5953\n",
      "Epoch 25/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6384 - accuracy: 0.5976 - val_loss: 0.6558 - val_accuracy: 0.6019\n",
      "Epoch 26/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6395 - accuracy: 0.5978 - val_loss: 0.6559 - val_accuracy: 0.5961\n",
      "Epoch 27/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6375 - accuracy: 0.6003 - val_loss: 0.6564 - val_accuracy: 0.6005\n",
      "Epoch 28/30\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.6378 - accuracy: 0.6002 - val_loss: 0.6595 - val_accuracy: 0.5973\n",
      "Epoch 29/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6371 - accuracy: 0.6014 - val_loss: 0.6591 - val_accuracy: 0.5993\n",
      "Epoch 30/30\n",
      "291/291 [==============================] - 1s 4ms/step - loss: 0.6367 - accuracy: 0.6016 - val_loss: 0.6631 - val_accuracy: 0.5971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1535107f0>"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=30, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.5971\n",
      "Test accuracy = 59.71%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f'Test accuracy = {100*acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_logit_preds = model.predict(test_ds).squeeze()\n",
    "nn_softmax_preds = tf.nn.sigmoid(nn_logit_preds)\n",
    "nn_preds = tf.round(nn_softmax_preds).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly accuracy\n",
    "\n",
    "Compare the monthly accuracy for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_accuracy(model, df, is_tf=False):\n",
    "    monthly_acc = []\n",
    "    months_list = np.sort(df['M'].unique())\n",
    "    for months in months_list:\n",
    "        test_month = df[df['M'] == months]\n",
    "\n",
    "        y_test_month = test_month.pop('home_win')\n",
    "        X_test_month = test_month\n",
    "\n",
    "        if is_tf:\n",
    "            tf_ds = tf.data.Dataset.from_tensor_slices((dict(X_test_month), y_test_month)).batch(128)\n",
    "            test_logits = model.predict(tf_ds).squeeze()\n",
    "            pred = tf.round(tf.nn.sigmoid(test_logits)).numpy()\n",
    "        else:\n",
    "            pred = model.predict(X_test_month)\n",
    "        acc = accuracy_score(y_test_month, pred)\n",
    "\n",
    "        monthly_acc.append(acc)\n",
    "\n",
    "    monthly_acc = pd.DataFrame(monthly_acc)\n",
    "    \n",
    "    return monthly_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_month = monthly_accuracy(xgb_clf, test_df)\n",
    "knn_month = monthly_accuracy(knn_clf, test_df_scaled)\n",
    "knn_no_ops_month = monthly_accuracy(knn_no_ops_clf, test_df_scaled.drop('ops_pct_diff', axis=1))\n",
    "tf_test_df['home_win'] = y_test\n",
    "nn_month = monthly_accuracy(model, tf_test_df, is_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(xgb_month[0]*100, label='XGB')\n",
    "plt.plot(knn_month[0]*100, label='KNN')\n",
    "plt.plot(nn_month[0]*100, label='NN')\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.xticks(range(8), ['March','April', 'May', 'June','July', 'August', 'September', 'October'])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative stats\n",
    "\n",
    "Consider stats like `ops_pct_diff` where a positive value is a strong indicator of a win for the home team. In the case where these stats are _negative_ and yet the home team still wins (or positive but the away team wins), how is each model performing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_df['home_win'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>avg_pct_diff</th>\n",
       "      <th>obp_pct_diff</th>\n",
       "      <th>slg_pct_diff</th>\n",
       "      <th>team_ERA_pct_diff</th>\n",
       "      <th>team_WHIP_pct_diff</th>\n",
       "      <th>team_W-L_pct_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>log_5</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>nn_pred</th>\n",
       "      <th>xgb_proba</th>\n",
       "      <th>knn_proba</th>\n",
       "      <th>nn_proba</th>\n",
       "      <th>home_win</th>\n",
       "      <th>knn_no_ops_pred</th>\n",
       "      <th>knn_no_ops_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36441</th>\n",
       "      <td>KCA</td>\n",
       "      <td>NYN</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>8.620726</td>\n",
       "      <td>3.092675</td>\n",
       "      <td>2.578581</td>\n",
       "      <td>7.754011</td>\n",
       "      <td>8.007859</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562908</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.590414</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36442</th>\n",
       "      <td>PIT</td>\n",
       "      <td>SLN</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2.309712</td>\n",
       "      <td>0.376945</td>\n",
       "      <td>-0.040732</td>\n",
       "      <td>8.978328</td>\n",
       "      <td>-1.211283</td>\n",
       "      <td>-2.040816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.563689</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36443</th>\n",
       "      <td>TBA</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.864577</td>\n",
       "      <td>-7.555239</td>\n",
       "      <td>-12.023378</td>\n",
       "      <td>-1.871658</td>\n",
       "      <td>1.468752</td>\n",
       "      <td>-16.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.666198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36444</th>\n",
       "      <td>ANA</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>-4.950458</td>\n",
       "      <td>-0.794957</td>\n",
       "      <td>14.720812</td>\n",
       "      <td>8.900281</td>\n",
       "      <td>-14.117647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450952</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.531114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36445</th>\n",
       "      <td>ARI</td>\n",
       "      <td>COL</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.095675</td>\n",
       "      <td>2.427164</td>\n",
       "      <td>-5.196744</td>\n",
       "      <td>-24.444444</td>\n",
       "      <td>-13.778463</td>\n",
       "      <td>13.924051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584152</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_team away_team     Y  M  avg_pct_diff  obp_pct_diff  slg_pct_diff  \\\n",
       "36441       KCA       NYN  2016  4      8.620726      3.092675      2.578581   \n",
       "36442       PIT       SLN  2016  4      2.309712      0.376945     -0.040732   \n",
       "36443       TBA       TOR  2016  4     -5.864577     -7.555239    -12.023378   \n",
       "36444       ANA       CHN  2016  4      0.398896     -4.950458     -0.794957   \n",
       "36445       ARI       COL  2016  4     -1.095675      2.427164     -5.196744   \n",
       "\n",
       "       team_ERA_pct_diff  team_WHIP_pct_diff  team_W-L_pct_diff  ...  log_5  \\\n",
       "36441           7.754011            8.007859           5.263158  ...    0.5   \n",
       "36442           8.978328           -1.211283          -2.040816  ...    0.5   \n",
       "36443          -1.871658            1.468752         -16.250000  ...    0.5   \n",
       "36444          14.720812            8.900281         -14.117647  ...    0.5   \n",
       "36445         -24.444444          -13.778463          13.924051  ...    0.5   \n",
       "\n",
       "       xgb_pred  knn_pred  nn_pred  xgb_proba  knn_proba  nn_proba  home_win  \\\n",
       "36441         1         1        1   0.562908   0.533333  0.590414         1   \n",
       "36442         1         0        1   0.533676   0.493333  0.563689         1   \n",
       "36443         0         1        1   0.454400   0.566667  0.666198         0   \n",
       "36444         0         0        1   0.450952   0.460000  0.531114         0   \n",
       "36445         1         0        1   0.584152   0.446667  0.562535         0   \n",
       "\n",
       "       knn_no_ops_pred  knn_no_ops_proba  \n",
       "36441                1          0.533333  \n",
       "36442                1          0.506667  \n",
       "36443                1          0.593333  \n",
       "36444                0          0.420000  \n",
       "36445                0          0.466667  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_stats_acc(df, col, reverse=False):\n",
    "    if not reverse:\n",
    "        unusual_df = df[((df[col] > 0) & (df['home_win'] == 0)) | ((df[col] < 0) & (df['home_win'] == 1))]\n",
    "    else:\n",
    "        unusual_df = df[((df[col] < 0) & (df['home_win'] == 0)) | ((df[col] > 0) & (df['home_win'] == 1))]\n",
    "    \n",
    "    xgb_acc = (unusual_df['xgb_pred'] == unusual_df['home_win']).sum() / unusual_df.shape[0]\n",
    "    nn_acc = (unusual_df['nn_pred'] == unusual_df['home_win']).sum() / unusual_df.shape[0]\n",
    "    knn_acc = (unusual_df['knn_pred'] == unusual_df['home_win']).sum() / unusual_df.shape[0]\n",
    "    knn_no_ops_acc = (unusual_df['knn_no_ops_pred'] == unusual_df['home_win']).sum() / unusual_df.shape[0]\n",
    "    \n",
    "    print(f'{\"=\"*10} {col} {\"=\"*10}')\n",
    "    print(f'XGB acc = {100*xgb_acc:.2f}%')\n",
    "    print(f'NN acc = {100*nn_acc:.2f}%')\n",
    "    print(f'KNN acc = {100*knn_acc:.2f}%')\n",
    "    print(f'KNN (no OPS) acc = {100*knn_no_ops_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_cols = ['team_ERA_pct_diff', 'pitcher_ERA_pct_diff', 'team_WHIP_pct_diff',\n",
    "                'pitcher_WHIP_pct_diff', 'team_Rank_pct_diff', 'Rank_pct_diff']\n",
    "pct_diff_cols = [c for c in tf_test_df.columns if c.endswith('_pct_diff')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in reverse_cols:\n",
    "    pct_diff_cols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== avg_pct_diff ==========\n",
      "XGB acc = 31.32%\n",
      "NN acc = 26.86%\n",
      "KNN acc = 27.62%\n",
      "KNN (no OPS) acc = 27.29%\n",
      "========== obp_pct_diff ==========\n",
      "XGB acc = 26.99%\n",
      "NN acc = 24.87%\n",
      "KNN acc = 24.55%\n",
      "KNN (no OPS) acc = 24.76%\n",
      "========== slg_pct_diff ==========\n",
      "XGB acc = 27.15%\n",
      "NN acc = 22.95%\n",
      "KNN acc = 25.77%\n",
      "KNN (no OPS) acc = 27.76%\n",
      "========== team_W-L_pct_diff ==========\n",
      "XGB acc = 51.64%\n",
      "NN acc = 55.34%\n",
      "KNN acc = 48.38%\n",
      "KNN (no OPS) acc = 48.10%\n",
      "========== team_FP_pct_diff ==========\n",
      "XGB acc = 59.50%\n",
      "NN acc = 61.55%\n",
      "KNN acc = 57.47%\n",
      "KNN (no OPS) acc = 57.61%\n",
      "========== R_pct_diff ==========\n",
      "XGB acc = 54.32%\n",
      "NN acc = 54.22%\n",
      "KNN acc = 49.10%\n",
      "KNN (no OPS) acc = 48.97%\n",
      "========== RA_pct_diff ==========\n",
      "XGB acc = 70.13%\n",
      "NN acc = 67.08%\n",
      "KNN acc = 70.99%\n",
      "KNN (no OPS) acc = 71.23%\n",
      "========== pytha_pct_diff ==========\n",
      "XGB acc = 50.92%\n",
      "NN acc = 53.32%\n",
      "KNN acc = 47.52%\n",
      "KNN (no OPS) acc = 47.26%\n",
      "========== win_pct_diff ==========\n",
      "XGB acc = 52.21%\n",
      "NN acc = 53.85%\n",
      "KNN acc = 48.41%\n",
      "KNN (no OPS) acc = 48.12%\n",
      "========== bayes_pct_diff ==========\n",
      "XGB acc = 57.55%\n",
      "NN acc = 59.09%\n",
      "KNN acc = 56.37%\n",
      "KNN (no OPS) acc = 55.88%\n",
      "========== pitcher_IP_pct_diff ==========\n",
      "XGB acc = 54.15%\n",
      "NN acc = 57.03%\n",
      "KNN acc = 58.02%\n",
      "KNN (no OPS) acc = 57.85%\n",
      "========== ops_pct_diff ==========\n",
      "XGB acc = 21.52%\n",
      "NN acc = 18.02%\n",
      "KNN acc = 20.62%\n",
      "KNN (no OPS) acc = 22.50%\n",
      "========== RD_pct_diff ==========\n",
      "XGB acc = 57.69%\n",
      "NN acc = 60.33%\n",
      "KNN acc = 57.45%\n",
      "KNN (no OPS) acc = 56.91%\n",
      "========== FP_pct_diff ==========\n",
      "XGB acc = 59.50%\n",
      "NN acc = 61.55%\n",
      "KNN acc = 57.47%\n",
      "KNN (no OPS) acc = 57.61%\n",
      "========== WPA_pct_diff ==========\n",
      "XGB acc = 56.01%\n",
      "NN acc = 58.79%\n",
      "KNN acc = 55.56%\n",
      "KNN (no OPS) acc = 55.24%\n"
     ]
    }
   ],
   "source": [
    "for c in pct_diff_cols:\n",
    "    negative_stats_acc(tf_test_df, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== team_ERA_pct_diff ==========\n",
      "XGB acc = 53.05%\n",
      "NN acc = 55.55%\n",
      "KNN acc = 49.51%\n",
      "KNN (no OPS) acc = 49.21%\n",
      "========== pitcher_ERA_pct_diff ==========\n",
      "XGB acc = 61.37%\n",
      "NN acc = 59.52%\n",
      "KNN acc = 61.23%\n",
      "KNN (no OPS) acc = 61.41%\n",
      "========== team_WHIP_pct_diff ==========\n",
      "XGB acc = 53.26%\n",
      "NN acc = 55.71%\n",
      "KNN acc = 50.12%\n",
      "KNN (no OPS) acc = 49.77%\n",
      "========== pitcher_WHIP_pct_diff ==========\n",
      "XGB acc = 56.96%\n",
      "NN acc = 57.73%\n",
      "KNN acc = 56.55%\n",
      "KNN (no OPS) acc = 56.22%\n",
      "========== team_Rank_pct_diff ==========\n",
      "XGB acc = 50.88%\n",
      "NN acc = 55.41%\n",
      "KNN acc = 47.78%\n",
      "KNN (no OPS) acc = 47.39%\n",
      "========== Rank_pct_diff ==========\n",
      "XGB acc = 50.88%\n",
      "NN acc = 55.41%\n",
      "KNN acc = 47.78%\n",
      "KNN (no OPS) acc = 47.39%\n"
     ]
    }
   ],
   "source": [
    "for c in reverse_cols:\n",
    "    negative_stats_acc(tf_test_df, c, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xgb_top10_preds.shape == knn_preds.shape == nn_preds.shape == knn_no_ops_preds.shape == y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual model accuracy:\n",
      "XGB: 61.08%\n",
      "KNN: 61.56%\n",
      "KNN (no hitting): 60.89%\n",
      "NN: 61.40%\n"
     ]
    }
   ],
   "source": [
    "print('Individual model accuracy:')\n",
    "print(f'XGB: {100*accuracy_score(y_test, xgb_preds):.2f}%')\n",
    "print(f'KNN: {100*accuracy_score(y_test, knn_preds):.2f}%')\n",
    "print(f'KNN (no hitting): {100*accuracy_score(y_test, knn_no_ops_preds):.2f}%')\n",
    "print(f'NN: {100*accuracy_score(y_test, nn_preds):.2f}%')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB (all) <-> XGB (top 10): 1711 disagreed on\n",
      "Maximum possible accuracy = 70.34%\n",
      "========================================\n",
      "XGB (all) <-> KNN (top 10): 1882 disagreed on\n",
      "Maximum possible accuracy = 70.79%\n",
      "========================================\n",
      "XGB (all) <-> KNN (top 10, no hitting): 2133 disagreed on\n",
      "Maximum possible accuracy = 71.71%\n",
      "========================================\n",
      "XGB (all) <-> NN (top 10): 2038 disagreed on\n",
      "Maximum possible accuracy = 71.49%\n",
      "========================================\n",
      "XGB (top 10) <-> KNN (top 10): 1403 disagreed on\n",
      "Maximum possible accuracy = 69.03%\n",
      "========================================\n",
      "XGB (top 10) <-> KNN (top 10, no hitting): 1844 disagreed on\n",
      "Maximum possible accuracy = 70.91%\n",
      "========================================\n",
      "XGB (top 10) <-> NN (top 10): 1501 disagreed on\n",
      "Maximum possible accuracy = 69.44%\n",
      "========================================\n",
      "KNN (top 10) <-> KNN (top 10, no hitting): 921 disagreed on\n",
      "Maximum possible accuracy = 65.86%\n",
      "========================================\n",
      "KNN (top 10) <-> NN (top 10): 1536 disagreed on\n",
      "Maximum possible accuracy = 69.21%\n",
      "========================================\n",
      "KNN (top 10, no hitting) <-> NN (top 10): 1797 disagreed on\n",
      "Maximum possible accuracy = 70.19%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "preds_names = ['XGB (all)', 'XGB (top 10)', 'KNN (top 10)', 'KNN (top 10, no hitting)', 'NN (top 10)']\n",
    "preds_list = [xgb_preds, xgb_top10_preds, knn_preds, knn_no_ops_preds, nn_preds]\n",
    "\n",
    "for idx1, idx2 in combinations(range(len(preds_list)), 2):\n",
    "    model1 = preds_list[idx1]\n",
    "    model2 = preds_list[idx2]\n",
    "    disagree = np.sum(model1 != model2)\n",
    "    print(f'{preds_names[idx1]} <-> {preds_names[idx2]}: {disagree} disagreed on')\n",
    "    \n",
    "    num_correct = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test.values[i] in [model1[i], model2[i]]:\n",
    "            num_correct += 1\n",
    "\n",
    "    print(f'Maximum possible accuracy = {100*num_correct / y_test.shape[0]:.2f}%')\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB (all), XGB (top 10), KNN (top 10)\n",
      "Maximum possible accuracy = 73.94%\n",
      "========================================\n",
      "XGB (all), XGB (top 10), KNN (top 10, no hitting)\n",
      "Maximum possible accuracy = 75.46%\n",
      "========================================\n",
      "XGB (all), XGB (top 10), NN (top 10)\n",
      "Maximum possible accuracy = 74.49%\n",
      "========================================\n",
      "XGB (all), KNN (top 10), KNN (top 10, no hitting)\n",
      "Maximum possible accuracy = 73.46%\n",
      "========================================\n",
      "XGB (all), KNN (top 10), NN (top 10)\n",
      "Maximum possible accuracy = 74.85%\n",
      "========================================\n",
      "XGB (all), KNN (top 10, no hitting), NN (top 10)\n",
      "Maximum possible accuracy = 75.76%\n",
      "========================================\n",
      "XGB (top 10), KNN (top 10), KNN (top 10, no hitting)\n",
      "Maximum possible accuracy = 72.13%\n",
      "========================================\n",
      "XGB (top 10), KNN (top 10), NN (top 10)\n",
      "Maximum possible accuracy = 72.81%\n",
      "========================================\n",
      "XGB (top 10), KNN (top 10, no hitting), NN (top 10)\n",
      "Maximum possible accuracy = 74.20%\n",
      "========================================\n",
      "KNN (top 10), KNN (top 10, no hitting), NN (top 10)\n",
      "Maximum possible accuracy = 71.86%\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for idx1, idx2, idx3 in combinations(range(len(preds_list)), 3):\n",
    "    model1 = preds_list[idx1]\n",
    "    model2 = preds_list[idx2]\n",
    "    model3 = preds_list[idx3]\n",
    "\n",
    "    num_correct = 0\n",
    "    for i in range(y_test.shape[0]):\n",
    "        if y_test.values[i] in [model1[i], model2[i], model3[i]]:\n",
    "            num_correct += 1\n",
    "    print(f'{preds_names[idx1]}, {preds_names[idx2]}, {preds_names[idx3]}')\n",
    "    print(f'Maximum possible accuracy = {100*num_correct / y_test.shape[0]:.2f}%')\n",
    "    print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum possible accuracy\n",
    "\n",
    "If we could always pick the \"right\" model for each row, what is the best possible test accuracy we could get from these three models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum possible accuracy = 74.20%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    if y_test.values[i] in [xgb_top10_preds[i], knn_no_ops_preds[i], nn_preds[i]]:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Maximum possible accuracy = {100*num_correct / y_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority voting\n",
    "\n",
    "Just pick the prediction that the majority of the models voted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting accuracy = 62.14%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    # Just add them up. If at least two models voted 1, then choose 1. Otherwise choose 0.\n",
    "    majority_vote = np.sum([xgb_top10_preds[i], knn_no_ops_preds[i], nn_preds[i]])\n",
    "    if majority_vote > 1:\n",
    "        majority_vote = 1\n",
    "    else:\n",
    "        majority_vote = 0\n",
    "    if y_test.values[i] == majority_vote:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Majority voting accuracy = {100*num_correct / y_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of positive columns\n",
    "Choose a KNN when the number of positive columns (from list below) is < 5, and the NN when it's greater than 5. This work/idea comes from the `Comparing model predictions` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_diff_cols = [c for c in cols if c.endswith('_pct_diff')]\n",
    "pct_diff_reverse_cols = ['pitcher_WHIP_pct_diff', 'team_Rank_pct_diff', \n",
    "                         'team_WHIP_pct_diff', 'team_ERA_pct_diff', 'pitcher_ERA_pct_diff',\n",
    "                         'team_RA_pct_diff']\n",
    "pct_diff_reverse_cols = list(set(pct_diff_cols).intersection(pct_diff_reverse_cols))\n",
    "\n",
    "for c in pct_diff_reverse_cols:\n",
    "    pct_diff_cols.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting accuracy = 61.81%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    # Just add them up. If at least two models voted 1, then choose 1. Otherwise choose 0.\n",
    "    vote = np.sum([knn_no_ops_preds[i], nn_preds[i]])\n",
    "    if vote == 2:\n",
    "        vote = 1\n",
    "    elif vote == 0:\n",
    "        vote = 0\n",
    "    elif (test_df.iloc[i][pct_diff_cols] > 0).sum() >= 5:\n",
    "        vote = knn_no_ops_preds[i]\n",
    "    else:\n",
    "        vote = nn_preds[i]\n",
    "        \n",
    "    if y_test.values[i] == vote:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Majority voting accuracy = {100*num_correct / y_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting accuracy = 61.82%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    # Just add them up. If at least two models voted 1, then choose 1. Otherwise choose 0.\n",
    "    vote = np.sum([knn_no_ops_preds[i], nn_preds[i]])\n",
    "    if vote == 2:\n",
    "        vote = 1\n",
    "    elif vote == 0:\n",
    "        vote = 0\n",
    "    elif (test_df.iloc[i][pct_diff_reverse_cols] < 0).sum() >= 4:\n",
    "        vote = knn_no_ops_preds[i]\n",
    "    else:\n",
    "        vote = nn_preds[i]\n",
    "        \n",
    "    if y_test.values[i] == vote:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Majority voting accuracy = {100*num_correct / y_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting accuracy = 61.71%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    # Just add them up. If at least two models voted 1, then choose 1. Otherwise choose 0.\n",
    "    vote = np.sum([knn_no_ops_preds[i], nn_preds[i]])\n",
    "    if vote == 2:\n",
    "        vote = 1\n",
    "    elif vote == 0:\n",
    "        vote = 0\n",
    "    elif test_df.iloc[i]['team_bayes_pct_diff'] > 0:\n",
    "        vote = nn_preds[i]\n",
    "    else:\n",
    "        vote = knn_no_ops_preds[i]\n",
    "        \n",
    "    if y_test.values[i] == vote:\n",
    "        num_correct += 1\n",
    "\n",
    "print(f'Majority voting accuracy = {100*num_correct / y_test.shape[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording predictions\n",
    "\n",
    "Save a dataframe with the predictions for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_ops_pct_diff</th>\n",
       "      <th>obp_diff</th>\n",
       "      <th>team_obp_pct_diff</th>\n",
       "      <th>home_Rank_offset1year</th>\n",
       "      <th>away_WHIP_offset1year</th>\n",
       "      <th>team_ERA_pct_diff</th>\n",
       "      <th>home_win_diff_bayes</th>\n",
       "      <th>home_RD</th>\n",
       "      <th>team_bayes_pct_diff</th>\n",
       "      <th>away_win_diff_bayes</th>\n",
       "      <th>...</th>\n",
       "      <th>away_pitcher_IP_avg_162games</th>\n",
       "      <th>team_Rank_pct_diff</th>\n",
       "      <th>home_pitcher_IP_avg_162games</th>\n",
       "      <th>away_RD</th>\n",
       "      <th>home_pitcher_WHIP_avg_162games</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>home_win</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37193</th>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.253927</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>SLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>-0.100639</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.075552</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.214434</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TBA</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>0.028053</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.030927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.179045</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCA</td>\n",
       "      <td>NYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196</th>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.019876</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.320066</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>CHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>-0.026164</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.151872</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANA</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_ops_pct_diff  obp_diff  team_obp_pct_diff  home_Rank_offset1year  \\\n",
       "37193           0.001479  0.001196           0.003769                    2.0   \n",
       "37194          -0.100639 -0.023374          -0.075552                    4.0   \n",
       "37195           0.028053  0.009820           0.030927                    1.0   \n",
       "37196           0.031095  0.006132           0.019876                    5.0   \n",
       "37197          -0.026164 -0.014945          -0.049505                    3.0   \n",
       "\n",
       "       away_WHIP_offset1year  team_ERA_pct_diff  home_win_diff_bayes  home_RD  \\\n",
       "37193               1.253927           0.089783            -0.010464    101.0   \n",
       "37194               1.214434          -0.018717            -0.010464      2.0   \n",
       "37195               1.179045           0.077540            -0.010464     83.0   \n",
       "37196               1.320066           0.043269            -0.010464    -35.0   \n",
       "37197               1.151872           0.147208            -0.010464    -14.0   \n",
       "\n",
       "       team_bayes_pct_diff  away_win_diff_bayes  ...  \\\n",
       "37193                  0.0            -0.010464  ...   \n",
       "37194                  0.0            -0.010464  ...   \n",
       "37195                  0.0            -0.010464  ...   \n",
       "37196                  0.0            -0.010464  ...   \n",
       "37197                  0.0            -0.010464  ...   \n",
       "\n",
       "       away_pitcher_IP_avg_162games  team_Rank_pct_diff  \\\n",
       "37193                      5.485714                0.50   \n",
       "37194                      5.485714                0.75   \n",
       "37195                      5.485714                0.00   \n",
       "37196                      5.485714                0.20   \n",
       "37197                      5.485714                0.00   \n",
       "\n",
       "       home_pitcher_IP_avg_162games  away_RD  home_pitcher_WHIP_avg_162games  \\\n",
       "37193                      5.480001    122.0                        1.390555   \n",
       "37194                      5.480001    221.0                        1.390555   \n",
       "37195                      5.480001     70.0                        1.390555   \n",
       "37196                      5.480001    -79.0                        1.390555   \n",
       "37197                      5.480001     81.0                        1.390555   \n",
       "\n",
       "          Y    M  home_win  home_team  away_team  \n",
       "37193  2016  4.0       1.0        PIT        SLN  \n",
       "37194  2016  4.0       0.0        TBA        TOR  \n",
       "37195  2016  4.0       1.0        KCA        NYN  \n",
       "37196  2016  4.0       0.0        OAK        CHA  \n",
       "37197  2016  4.0       0.0        ANA        CHN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_nn['home_team'] = le.inverse_transform(test_df_nn['home_team'])\n",
    "test_df_nn['away_team'] = le.inverse_transform(test_df_nn['away_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_ops_pct_diff</th>\n",
       "      <th>obp_diff</th>\n",
       "      <th>team_obp_pct_diff</th>\n",
       "      <th>home_Rank_offset1year</th>\n",
       "      <th>away_WHIP_offset1year</th>\n",
       "      <th>team_ERA_pct_diff</th>\n",
       "      <th>home_win_diff_bayes</th>\n",
       "      <th>home_RD</th>\n",
       "      <th>team_bayes_pct_diff</th>\n",
       "      <th>away_win_diff_bayes</th>\n",
       "      <th>...</th>\n",
       "      <th>away_pitcher_IP_avg_162games</th>\n",
       "      <th>team_Rank_pct_diff</th>\n",
       "      <th>home_pitcher_IP_avg_162games</th>\n",
       "      <th>away_RD</th>\n",
       "      <th>home_pitcher_WHIP_avg_162games</th>\n",
       "      <th>Y</th>\n",
       "      <th>M</th>\n",
       "      <th>home_win</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37193</th>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.253927</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>SLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>-0.100639</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.075552</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.214434</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TBA</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>0.028053</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.030927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.179045</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KCA</td>\n",
       "      <td>NYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196</th>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.019876</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.320066</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>CHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>-0.026164</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.151872</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.480001</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.390555</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ANA</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_ops_pct_diff  obp_diff  team_obp_pct_diff  home_Rank_offset1year  \\\n",
       "37193           0.001479  0.001196           0.003769                    2.0   \n",
       "37194          -0.100639 -0.023374          -0.075552                    4.0   \n",
       "37195           0.028053  0.009820           0.030927                    1.0   \n",
       "37196           0.031095  0.006132           0.019876                    5.0   \n",
       "37197          -0.026164 -0.014945          -0.049505                    3.0   \n",
       "\n",
       "       away_WHIP_offset1year  team_ERA_pct_diff  home_win_diff_bayes  home_RD  \\\n",
       "37193               1.253927           0.089783            -0.010464    101.0   \n",
       "37194               1.214434          -0.018717            -0.010464      2.0   \n",
       "37195               1.179045           0.077540            -0.010464     83.0   \n",
       "37196               1.320066           0.043269            -0.010464    -35.0   \n",
       "37197               1.151872           0.147208            -0.010464    -14.0   \n",
       "\n",
       "       team_bayes_pct_diff  away_win_diff_bayes  ...  \\\n",
       "37193                  0.0            -0.010464  ...   \n",
       "37194                  0.0            -0.010464  ...   \n",
       "37195                  0.0            -0.010464  ...   \n",
       "37196                  0.0            -0.010464  ...   \n",
       "37197                  0.0            -0.010464  ...   \n",
       "\n",
       "       away_pitcher_IP_avg_162games  team_Rank_pct_diff  \\\n",
       "37193                      5.485714                0.50   \n",
       "37194                      5.485714                0.75   \n",
       "37195                      5.485714                0.00   \n",
       "37196                      5.485714                0.20   \n",
       "37197                      5.485714                0.00   \n",
       "\n",
       "       home_pitcher_IP_avg_162games  away_RD  home_pitcher_WHIP_avg_162games  \\\n",
       "37193                      5.480001    122.0                        1.390555   \n",
       "37194                      5.480001    221.0                        1.390555   \n",
       "37195                      5.480001     70.0                        1.390555   \n",
       "37196                      5.480001    -79.0                        1.390555   \n",
       "37197                      5.480001     81.0                        1.390555   \n",
       "\n",
       "          Y    M  home_win  home_team  away_team  \n",
       "37193  2016  4.0       1.0        PIT        SLN  \n",
       "37194  2016  4.0       0.0        TBA        TOR  \n",
       "37195  2016  4.0       1.0        KCA        NYN  \n",
       "37196  2016  4.0       0.0        OAK        CHA  \n",
       "37197  2016  4.0       0.0        ANA        CHN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_nn['xgb_pred'] = xgb_preds\n",
    "test_df_nn['knn_pred'] = knn_preds\n",
    "test_df_nn['knn_no_batting_pred'] = knn_no_ops_preds\n",
    "test_df_nn['nn_pred'] = nn_preds\n",
    "test_df_nn['nn_pred'] = test_df_nn['nn_pred'].astype(int)\n",
    "\n",
    "test_df_nn['xgb_proba'] = xgb_proba_preds[:, 1]\n",
    "test_df_nn['knn_proba'] = knn_proba_preds[:, 1]\n",
    "test_df_nn['knn_no_batting_proba'] = knn_no_ops_proba_preds[:, 1]\n",
    "test_df_nn['nn_proba'] = nn_softmax_preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_ops_pct_diff</th>\n",
       "      <th>obp_diff</th>\n",
       "      <th>team_obp_pct_diff</th>\n",
       "      <th>home_Rank_offset1year</th>\n",
       "      <th>away_WHIP_offset1year</th>\n",
       "      <th>team_ERA_pct_diff</th>\n",
       "      <th>home_win_diff_bayes</th>\n",
       "      <th>home_RD</th>\n",
       "      <th>team_bayes_pct_diff</th>\n",
       "      <th>away_win_diff_bayes</th>\n",
       "      <th>...</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>knn_no_batting_pred</th>\n",
       "      <th>nn_pred</th>\n",
       "      <th>xgb_proba</th>\n",
       "      <th>knn_proba</th>\n",
       "      <th>knn_no_batting_proba</th>\n",
       "      <th>nn_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37193</th>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.253927</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>PIT</td>\n",
       "      <td>SLN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452681</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.455505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>-0.100639</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.075552</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.214434</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>TBA</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377228</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.395637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>0.028053</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.030927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.179045</td>\n",
       "      <td>0.077540</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>KCA</td>\n",
       "      <td>NYN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.629717</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.508145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196</th>\n",
       "      <td>0.031095</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.019876</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.320066</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>OAK</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572504</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.525333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>-0.026164</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.151872</td>\n",
       "      <td>0.147208</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010464</td>\n",
       "      <td>...</td>\n",
       "      <td>ANA</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515874</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.497620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       team_ops_pct_diff  obp_diff  team_obp_pct_diff  home_Rank_offset1year  \\\n",
       "37193           0.001479  0.001196           0.003769                    2.0   \n",
       "37194          -0.100639 -0.023374          -0.075552                    4.0   \n",
       "37195           0.028053  0.009820           0.030927                    1.0   \n",
       "37196           0.031095  0.006132           0.019876                    5.0   \n",
       "37197          -0.026164 -0.014945          -0.049505                    3.0   \n",
       "\n",
       "       away_WHIP_offset1year  team_ERA_pct_diff  home_win_diff_bayes  home_RD  \\\n",
       "37193               1.253927           0.089783            -0.010464    101.0   \n",
       "37194               1.214434          -0.018717            -0.010464      2.0   \n",
       "37195               1.179045           0.077540            -0.010464     83.0   \n",
       "37196               1.320066           0.043269            -0.010464    -35.0   \n",
       "37197               1.151872           0.147208            -0.010464    -14.0   \n",
       "\n",
       "       team_bayes_pct_diff  away_win_diff_bayes  ...  home_team  away_team  \\\n",
       "37193                  0.0            -0.010464  ...        PIT        SLN   \n",
       "37194                  0.0            -0.010464  ...        TBA        TOR   \n",
       "37195                  0.0            -0.010464  ...        KCA        NYN   \n",
       "37196                  0.0            -0.010464  ...        OAK        CHA   \n",
       "37197                  0.0            -0.010464  ...        ANA        CHN   \n",
       "\n",
       "       xgb_pred  knn_pred  knn_no_batting_pred  nn_pred  xgb_proba  knn_proba  \\\n",
       "37193       0.0       0.0                  1.0        0   0.452681   0.500000   \n",
       "37194       0.0       0.0                  1.0        0   0.377228   0.473333   \n",
       "37195       1.0       1.0                  1.0        1   0.629717   0.533333   \n",
       "37196       1.0       0.0                  1.0        1   0.572504   0.486667   \n",
       "37197       1.0       0.0                  0.0        0   0.515874   0.486667   \n",
       "\n",
       "       knn_no_batting_proba  nn_proba  \n",
       "37193              0.520000  0.455505  \n",
       "37194              0.506667  0.395637  \n",
       "37195              0.546667  0.508145  \n",
       "37196              0.506667  0.525333  \n",
       "37197              0.486667  0.497620  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_nn.to_csv('../data/Final Data/start_to_finish_with_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred = xgb_clf.predict(X_train)\n",
    "knn_no_train_pred = knn_no_ops_clf.predict(X_train_scaled_no_ops)\n",
    "nn_train_logit_preds = model.predict(train_ds).squeeze()\n",
    "nn_train_softmax_preds = tf.nn.sigmoid(nn_train_logit_preds)\n",
    "nn_train_pred = tf.round(nn_train_softmax_preds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_df['home_team'] = le.inverse_transform(tf_train_df['home_team'])\n",
    "tf_train_df['away_team'] = le.inverse_transform(tf_train_df['away_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_df['xgb_train_pred'] = xgb_train_pred\n",
    "tf_train_df['knn_no_batting_train_pred'] = knn_no_train_pred\n",
    "tf_train_df['nn_train_pred'] = nn_train_pred\n",
    "tf_train_df['nn_train_pred'] = tf_train_df['nn_train_pred'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_df['home_win'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_df.to_csv('../data/Final Data/training_with_preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
